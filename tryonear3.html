<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AR Earring Try-On</title>

    <!-- MediaPipe & TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

    <style>
        body {
            text-align: center;
            font-family: "Poppins", sans-serif;
            background: linear-gradient(135deg, #1c1c1c, #3a3a3a);
            color: #fff;
            padding: 20px;
        }
        h2 {
            font-size: 28px;
            margin-bottom: 15px;
            text-transform: uppercase;
        }
        .video-container {
            position: relative;
            display: flex;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(255, 215, 0, 0.3);
        }
        video, canvas {
            display: block;
            width: 100%;
        }
        .btn {
            background: linear-gradient(135deg, #b79c65, #e7c888);
            color: white;
            font-size: 16px;
            font-weight: bold;
            margin-top: 15px;
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(231, 200, 136, 0.4);
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .btn:hover {
            background: linear-gradient(135deg, #e7c888, #b79c65);
            box-shadow: 0 6px 20px rgba(231, 200, 136, 0.6);
            transform: translateY(-3px);
        }
    </style>
</head>
<body>

    <h2>AR Earring Try-On</h2>

    <div class="video-container">
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>

    <button class="btn" id="captureBtn">Capture & Download</button>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const earringImg = new Image();
        earringImg.src = "image/earring_2_tryon.png"; // Ensure this path is correct

        // Debugging: Log when the earring image loads
        earringImg.onload = () => {
            console.log("Earring image loaded successfully.");
        };
        earringImg.onerror = () => {
            console.error("Failed to load earring image. Check the path.");
        };

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    console.log("Camera started. Video dimensions:", canvas.width, canvas.height);
                };
            } catch (error) {
                console.error("Error accessing camera:", error);
            }
        }

        async function loadFaceTracking() {
            const faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
            faceMesh.setOptions({
                maxNumFaces: 1,
                minDetectionConfidence: 0.7,
                minTrackingConfidence: 0.7
            });
            faceMesh.onResults(drawEarrings);

            const camera = new Camera(video, {
                onFrame: async () => {
                    await faceMesh.send({ image: video });
                },
                width: 640,
                height: 480
            });
            camera.start();
            console.log("Face Mesh initialized.");
        }

        function drawEarrings(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const face = results.multiFaceLandmarks[0];
                const leftEar = face[234]; // Left ear landmark
                const rightEar = face[454]; // Right ear landmark

                // Draw left earring only if the left ear landmark is detected
                if (leftEar) {
                    const leftX = leftEar.x * canvas.width -15;
                    const leftY = leftEar.y * canvas.height + 10;
                    ctx.drawImage(earringImg, leftX, leftY, 20, 20);
                    console.log("Left earring drawn at:", leftX, leftY);
                }

                // Draw right earring only if the right ear landmark is detected
                if (rightEar) {
                    const rightX = rightEar.x * canvas.width - 10 ;
                    const rightY = rightEar.y * canvas.height + 10;
                    ctx.drawImage(earringImg, rightX, rightY, 20, 20);
                    console.log("Right earring drawn at:", rightX, rightY);
                }
            }
        }

        document.getElementById("captureBtn").addEventListener("click", () => {
            const link = document.createElement("a");
            link.download = "earring_tryon.png";
            link.href = canvas.toDataURL("image/png");
            link.click();
            console.log("Image captured and downloaded.");
        });

        startCamera();
        loadFaceTracking();
    </script>

</body>
</html>